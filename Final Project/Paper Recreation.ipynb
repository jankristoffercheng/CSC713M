{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thumbs up? Sentiment Classification using Machine Learning Techniques\n",
    "by Bo Pang, Lillian Lee and Shivakumar Vaithyanathan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative: 700\n",
      "Positive: 700\n",
      "Total: 1400\n"
     ]
    }
   ],
   "source": [
    "from file_reader import FileReader\n",
    "\n",
    "negPath = 'mix20_rand700_tokens_cleaned/tokens/neg/'\n",
    "posPath = 'mix20_rand700_tokens_cleaned/tokens/pos/'\n",
    "\n",
    "fileReader = FileReader()\n",
    "\n",
    "negatives = fileReader.getTexts(negPath)\n",
    "positives = fileReader.getTexts(posPath)\n",
    "allTexts = negatives + positives\n",
    "\n",
    "print('Negative:', len(negatives))\n",
    "print('Positive:', len(positives))\n",
    "print('Total:', len(allTexts))\n",
    "\n",
    "N = len(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "233\n"
     ]
    }
   ],
   "source": [
    "nFold = 3\n",
    "nPerFold = int(N/nFold)\n",
    "print(nPerFold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Negation for unigram feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from features import TextNegator\n",
    "\n",
    "textNegator = TextNegator()\n",
    "\n",
    "negatedNegatives = textNegator.getNegated(negatives)\n",
    "negatedPositives = textNegator.getNegated(positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700\n"
     ]
    }
   ],
   "source": [
    "print(len(negatedNegatives))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get unigrams of negated texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from features import UnigramFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from k_fold import KFoldBatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "kfold = KFold(nFold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: unigrams frequency\n",
      "Number of Features: 15479\n",
      "Naive Bayes Accuracy: 0.761802575107\n",
      "SVM Accuracy: 0.786123032904\n"
     ]
    }
   ],
   "source": [
    "results = {'features':[], 'nFeatures': [],'nb': [], 'svm': []}\n",
    "\n",
    "nbAccuracy = 0\n",
    "svmAccuracy = 0\n",
    "nFeatures = 0\n",
    "i = 0\n",
    "for trainIndex, testIndex in kfold.split(negatives):\n",
    "    unigramFeature = UnigramFeature()\n",
    "    unigramFeature.process([negatedNegatives[index] for index in trainIndex] + [negatedPositives[index] for index in trainIndex])\n",
    "    nFeatures += len(unigramFeature.unigrams)\n",
    "    \n",
    "    featuresNegative = unigramFeature.get(negatedNegatives, type='freq')\n",
    "    featuresPositive = unigramFeature.get(negatedPositives, type='freq')\n",
    "    \n",
    "    kfoldBatcher = KFoldBatcher(nFold, featuresNegative, featuresPositive)\n",
    "    trainX = kfoldBatcher.getTrainX(i)\n",
    "    trainY = kfoldBatcher.getTrainY(i)\n",
    "    \n",
    "    testX = kfoldBatcher.getTestX(i)\n",
    "    testY = kfoldBatcher.getTestY(i)\n",
    "    \n",
    "    nb = BernoulliNB()\n",
    "    nb.fit(trainX, trainY)\n",
    "    nbAccuracy += accuracy_score(nb.predict(testX), testY)\n",
    "\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(trainX, trainY)\n",
    "    svmAccuracy += accuracy_score(svm.predict(testX), testY)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "nbAccuracy /= nFold\n",
    "svmAccuracy /= nFold\n",
    "nFeatures = int(nFeatures/nFold)\n",
    "results['features'].append('unigrams')\n",
    "results['nFeatures'].append(nFeatures)\n",
    "results['nb'].append(nbAccuracy)\n",
    "results['svm'].append(svmAccuracy)\n",
    "\n",
    "print('Features: unigrams frequency')\n",
    "print('Number of Features:', nFeatures)\n",
    "print('Naive Bayes Accuracy:', nbAccuracy)\n",
    "print('SVM Accuracy:', svmAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: unigrams presence\n",
      "Number of Features: 15479\n",
      "Naive Bayes Accuracy: 0.761802575107\n",
      "SVM Accuracy: 0.804721030043\n"
     ]
    }
   ],
   "source": [
    "unigramFeaturesNegative = []\n",
    "unigramFeaturesPositive = []\n",
    "\n",
    "nbAccuracy = 0\n",
    "svmAccuracy = 0\n",
    "nFeatures = 0\n",
    "i = 0\n",
    "for trainIndex, testIndex in kfold.split(negatives):\n",
    "    unigramFeature = UnigramFeature()\n",
    "    unigramFeature.process([negatedNegatives[index] for index in trainIndex] + [negatedPositives[index] for index in trainIndex])\n",
    "    nFeatures += len(unigramFeature.unigrams)\n",
    "    \n",
    "    featuresNegative = unigramFeature.get(negatedNegatives, type='pres')\n",
    "    featuresPositive = unigramFeature.get(negatedPositives, type='pres')\n",
    "    \n",
    "    unigramFeaturesNegative.append(featuresNegative)\n",
    "    unigramFeaturesPositive.append(featuresPositive)\n",
    "\n",
    "    kfoldBatcher = KFoldBatcher(nFold, featuresNegative, featuresPositive)\n",
    "    \n",
    "    trainX = kfoldBatcher.getTrainX(i)\n",
    "    trainY = kfoldBatcher.getTrainY(i)\n",
    "    \n",
    "    testX = kfoldBatcher.getTestX(i)\n",
    "    testY = kfoldBatcher.getTestY(i)\n",
    "    \n",
    "    nb = BernoulliNB()\n",
    "    nb.fit(trainX, trainY)\n",
    "    nbAccuracy += accuracy_score(nb.predict(testX), testY)\n",
    "\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(trainX, trainY)\n",
    "    svmAccuracy += accuracy_score(svm.predict(testX), testY)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "nbAccuracy /= nFold\n",
    "svmAccuracy /= nFold\n",
    "nFeatures = int(nFeatures/nFold)\n",
    "results['features'].append('unigrams')\n",
    "results['nFeatures'].append(nFeatures)\n",
    "results['nb'].append(nbAccuracy)\n",
    "results['svm'].append(svmAccuracy)\n",
    "\n",
    "print('Features: unigrams presence')\n",
    "print('Number of Features:', nFeatures)\n",
    "print('Naive Bayes Accuracy:', nbAccuracy)\n",
    "print('SVM Accuracy:', svmAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from features import BigramFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: bigrams\n",
      "Number of Features: 0\n",
      "Naive Bayes Accuracy: 0.0\n",
      "SVM Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "bigramFeaturesNegative = []\n",
    "bigramFeaturesPositive = []\n",
    "\n",
    "nbAccuracy = 0\n",
    "svmAccuracy = 0\n",
    "nFeatures = 0\n",
    "i = 0\n",
    "for trainIndex, testIndex in kfold.split(negatives):\n",
    "    bigramFeature = BigramFeature()\n",
    "    bigramFeature.process([negatives[index] for index in trainIndex] + [positives[index] for index in trainIndex])\n",
    "    nFeatures += len(bigramFeature.bigrams)\n",
    "    \n",
    "    featuresNegative = bigramFeature.get(negatives)\n",
    "    featuresPositive = bigramFeature.get(positives)\n",
    "    \n",
    "    bigramFeaturesNegative.append(featuresNegative)\n",
    "    bigramFeaturesPositive.append(featuresPositive)\n",
    "\n",
    "    kfoldBatcher = KFoldBatcher(nFold, featuresNegative, featuresPositive)\n",
    "    \n",
    "    trainX = kfoldBatcher.getTrainX(i)\n",
    "    trainY = kfoldBatcher.getTrainY(i)\n",
    "    \n",
    "    testX = kfoldBatcher.getTestX(i)\n",
    "    testY = kfoldBatcher.getTestY(i)\n",
    "    \n",
    "    nb = BernoulliNB()\n",
    "    nb.fit(trainX, trainY)\n",
    "    nbAccuracy += accuracy_score(nb.predict(testX), testY)\n",
    "\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(trainX, trainY)\n",
    "    svmAccuracy += accuracy_score(svm.predict(testX), testY)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "nbAccuracy /= nFold\n",
    "svmAccuracy /= nFold\n",
    "nFeatures = int(nFeatures/nFold)\n",
    "results['features'].append('bigrams')\n",
    "results['nFeatures'].append(nFeatures)\n",
    "results['nb'].append(nbAccuracy)\n",
    "results['svm'].append(svmAccuracy)\n",
    "\n",
    "print('Features: bigrams')\n",
    "print('Number of Features:', nFeatures)\n",
    "print('Naive Bayes Accuracy:', nbAccuracy)\n",
    "print('SVM Accuracy:', svmAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigrams and Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-d30a7feaca1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnFold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mfeaturesNegative\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munigramFeaturesNegative\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbigramFeaturesNegative\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mfeaturesPositive\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0munigramFeaturesPositive\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbigramFeaturesPositive\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "bigramFeaturesNegative = []\n",
    "bigramFeaturesPositive = []\n",
    "\n",
    "nbAccuracy = 0\n",
    "svmAccuracy = 0\n",
    "nFeatures = 0\n",
    "for i in range(nFold):\n",
    "    print(i)\n",
    "    featuresNegative = np.concatenate((unigramFeaturesNegative[i], bigramFeaturesNegative[i]), axis=1)\n",
    "    featuresPositive = np.concatenate((unigramFeaturesPositive[i], bigramFeaturesPositive[i]), axis=1)\n",
    "\n",
    "    kfoldBatcher = KFoldBatcher(nFold, featuresNegative, featuresPositive)\n",
    "    \n",
    "    trainX = kfoldBatcher.getTrainX(i)\n",
    "    trainY = kfoldBatcher.getTrainY(i)\n",
    "    \n",
    "    testX = kfoldBatcher.getTestX(i)\n",
    "    testY = kfoldBatcher.getTestY(i)\n",
    "    \n",
    "    nb = BernoulliNB()\n",
    "    nb.fit(trainX, trainY)\n",
    "    nbAccuracy += accuracy_score(nb.predict(testX), testY)\n",
    "\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(trainX, trainY)\n",
    "    svmAccuracy += accuracy_score(svm.predict(testX), testY)\n",
    "    \n",
    "nbAccuracy /= nFold\n",
    "svmAccuracy /= nFold\n",
    "nFeatures = int(nFeatures/nFold)\n",
    "results['features'].append('unigrams+bigrams')\n",
    "results['nFeatures'].append(nFeatures)\n",
    "results['nb'].append(nbAccuracy)\n",
    "results['svm'].append(svmAccuracy)\n",
    "\n",
    "print('Features: unigrams+bigrams presence')\n",
    "print('Number of Features:', nFeatures)\n",
    "print('Naive Bayes Accuracy:', nbAccuracy)\n",
    "print('SVM Accuracy:', svmAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from features import UnigramPOSFeature\n",
    "from features import POSTagger\n",
    "\n",
    "posTagger = POSTagger()\n",
    "posNegatives = posTagger.getPOS(negatives)\n",
    "posPositives = posTagger.getPOS(positives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from features import AdjectiveFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: bigrams\n",
      "Number of Features: 12320\n",
      "Naive Bayes Accuracy: 0.776108726753\n",
      "SVM Accuracy: 0.760371959943\n"
     ]
    }
   ],
   "source": [
    "nbAccuracy = 0\n",
    "svmAccuracy = 0\n",
    "nFeatures = 0\n",
    "i = 0\n",
    "for trainIndex, testIndex in kfold.split(negatives):\n",
    "    adjFeature = AdjectiveFeature()\n",
    "    textsTrain = [negatives[index] for index in trainIndex] + [positives[index] for index in trainIndex]\n",
    "    posTextsTrain = [posNegatives[index] for index in trainIndex] + [posPositives[index] for index in trainIndex]\n",
    "    adjFeature.process(textsTrain, posTextsTrain)\n",
    "    nFeatures += len(adjFeature.adjectives)\n",
    "    \n",
    "    featuresNegative = adjFeature.get(negatives)\n",
    "    featuresPositive = adjFeature.get(positives)\n",
    "\n",
    "    kfoldBatcher = KFoldBatcher(nFold, featuresNegative, featuresPositive)\n",
    "    \n",
    "    trainX = kfoldBatcher.getTrainX(i)\n",
    "    trainY = kfoldBatcher.getTrainY(i)\n",
    "    \n",
    "    testX = kfoldBatcher.getTestX(i)\n",
    "    testY = kfoldBatcher.getTestY(i)\n",
    "    \n",
    "    nb = BernoulliNB()\n",
    "    nb.fit(trainX, trainY)\n",
    "    nbAccuracy += accuracy_score(nb.predict(testX), testY)\n",
    "\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(trainX, trainY)\n",
    "    svmAccuracy += accuracy_score(svm.predict(testX), testY)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "nbAccuracy /= nFold\n",
    "svmAccuracy /= nFold\n",
    "nFeatures = int(nFeatures/nFold)\n",
    "results['features'].append('adjectives')\n",
    "results['nFeatures'].append(nFeatures)\n",
    "results['nb'].append(nbAccuracy)\n",
    "results['svm'].append(svmAccuracy)\n",
    "\n",
    "print('Features: adjectives')\n",
    "print('Number of Features:', nFeatures)\n",
    "print('Naive Bayes Accuracy:', nbAccuracy)\n",
    "print('SVM Accuracy:', svmAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigrams + POS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: unigrams+POS\n",
      "Number of Features: 22\n",
      "Naive Bayes Accuracy: 0.585836909871\n",
      "SVM Accuracy: 0.581545064378\n"
     ]
    }
   ],
   "source": [
    "nbAccuracy = 0\n",
    "svmAccuracy = 0\n",
    "nFeatures = 0\n",
    "i = 0\n",
    "for trainIndex, testIndex in kfold.split(negatives):\n",
    "    unigramPOSFeature = UnigramPOSFeature()\n",
    "    negatedTextsTrain = [negatedNegatives[index] for index in trainIndex] + [negatedPositives[index] for index in trainIndex]\n",
    "    posTextsTrain = [posNegatives[index] for index in trainIndex] + [posPositives[index] for index in trainIndex]\n",
    "    unigramPOSFeature.process(negatedTextsTrain, posTextsTrain)\n",
    "    nFeatures += len(unigramPOSFeature.unigrams)\n",
    "    \n",
    "    featuresNegative = unigramPOSFeature.get(negatedNegatives, posNegatives)\n",
    "    featuresPositive = unigramPOSFeature.get(negatedPositives, posPositives)\n",
    "\n",
    "    kfoldBatcher = KFoldBatcher(nFold, featuresNegative, featuresPositive)\n",
    "    \n",
    "    trainX = kfoldBatcher.getTrainX(i)\n",
    "    trainY = kfoldBatcher.getTrainY(i)\n",
    "    \n",
    "    testX = kfoldBatcher.getTestX(i)\n",
    "    testY = kfoldBatcher.getTestY(i)\n",
    "    \n",
    "    nb = BernoulliNB()\n",
    "    nb.fit(trainX, trainY)\n",
    "    nbAccuracy += accuracy_score(nb.predict(testX), testY)\n",
    "\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(trainX, trainY)\n",
    "    svmAccuracy += accuracy_score(svm.predict(testX), testY)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "nbAccuracy /= nFold\n",
    "svmAccuracy /= nFold\n",
    "nFeatures = int(nFeatures/nFold)\n",
    "results['features'].append('unigrams+POS')\n",
    "results['nFeatures'].append(nFeatures)\n",
    "results['nb'].append(nbAccuracy)\n",
    "results['svm'].append(svmAccuracy)\n",
    "\n",
    "print('Features: unigrams+POS')\n",
    "print('Number of Features:', nFeatures)\n",
    "print('Naive Bayes Accuracy:', nbAccuracy)\n",
    "print('SVM Accuracy:', svmAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.--.', 'html--NN', '!--.', 'com--NN', 'com/--NN', 'michael%20redman--NN', 'com/ukcritic--JJ', '?--.', '|--NN', ')--)', 'bloom--NN', 'org/ejahiel--NN', '\"--NN', ')--n--)', '\"--n--VBP', 'edu/~jpeck1/--NN', '\"--n--NN', 'com/~mmapes/--NN', 'com/page/teenagemoviecritic--JJ', '\"--VB', '*--NN', 'net/~drsuess/--NN', 'com/film/--NN']\n"
     ]
    }
   ],
   "source": [
    "print(unigramPOSFeature.unigrams)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Top 2633 Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: unigrams+bigrams presence\n",
      "Number of Features: 0\n",
      "Naive Bayes Accuracy: 0.761802575107\n",
      "SVM Accuracy: 0.804721030043\n"
     ]
    }
   ],
   "source": [
    "nbAccuracy = 0\n",
    "svmAccuracy = 0\n",
    "nFeatures = 0\n",
    "for i in range(nFold):\n",
    "    featuresNegative = unigramFeaturesNegative[i][:2633]\n",
    "    featuresPositive = unigramFeaturesPositive[i][:2633]\n",
    "\n",
    "    kfoldBatcher = KFoldBatcher(nFold, featuresNegative, featuresPositive)\n",
    "    \n",
    "    trainX = kfoldBatcher.getTrainX(i)\n",
    "    trainY = kfoldBatcher.getTrainY(i)\n",
    "    \n",
    "    testX = kfoldBatcher.getTestX(i)\n",
    "    testY = kfoldBatcher.getTestY(i)\n",
    "    \n",
    "    nb = BernoulliNB()\n",
    "    nb.fit(trainX, trainY)\n",
    "    nbAccuracy += accuracy_score(nb.predict(testX), testY)\n",
    "\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(trainX, trainY)\n",
    "    svmAccuracy += accuracy_score(svm.predict(testX), testY)\n",
    "    \n",
    "nbAccuracy /= nFold\n",
    "svmAccuracy /= nFold\n",
    "nFeatures = 2633\n",
    "results['features'].append('top 2633 unigrams')\n",
    "results['nFeatures'].append(nFeatures)\n",
    "results['nb'].append(nbAccuracy)\n",
    "results['svm'].append(svmAccuracy)\n",
    "\n",
    "print('Features: top 2633 unigrams')\n",
    "print('Number of Features:', nFeatures)\n",
    "print('Naive Bayes Accuracy:', nbAccuracy)\n",
    "print('SVM Accuracy:', svmAccuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unigrams + position"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from features import PositionTagger\n",
    "\n",
    "positionTagger = PositionTagger()\n",
    "positionNegatives = positionTagger.getPositions(negatedNegatives)\n",
    "positionPositives = positionTagger.getPositions(negatedPositives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from features import UnigramPositionFeature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "932\n",
      "934\n",
      "934\n",
      "Features: unigrams+position\n",
      "Number of Features: 60\n",
      "Naive Bayes Accuracy: 0.582975679542\n",
      "SVM Accuracy: 0.590844062947\n"
     ]
    }
   ],
   "source": [
    "nbAccuracy = 0\n",
    "svmAccuracy = 0\n",
    "nFeatures = 0\n",
    "i = 0\n",
    "for trainIndex, testIndex in kfold.split(negatives):\n",
    "    unigramPositionFeature = UnigramPositionFeature()\n",
    "    negatedTextsTrain = [negatedNegatives[index] for index in trainIndex] + [negatedPositives[index] for index in trainIndex]\n",
    "    positionTextsTrain = [positionNegatives[index] for index in trainIndex] + [positionPositives[index] for index in trainIndex]\n",
    "    print(len(negatedTextsTrain))\n",
    "    unigramPositionFeature.process(negatedTextsTrain, positionTextsTrain)\n",
    "    nFeatures += len(unigramPositionFeature.unigrams)\n",
    "    \n",
    "    featuresNegative = unigramPositionFeature.get(negatedNegatives, positionNegatives)\n",
    "    featuresPositive = unigramPositionFeature.get(negatedPositives, positionPositives)\n",
    "\n",
    "    kfoldBatcher = KFoldBatcher(nFold, featuresNegative, featuresPositive)\n",
    "    \n",
    "    trainX = kfoldBatcher.getTrainX(i)\n",
    "    trainY = kfoldBatcher.getTrainY(i)\n",
    "    \n",
    "    testX = kfoldBatcher.getTestX(i)\n",
    "    testY = kfoldBatcher.getTestY(i)\n",
    "    \n",
    "    nb = BernoulliNB()\n",
    "    nb.fit(trainX, trainY)\n",
    "    nbAccuracy += accuracy_score(nb.predict(testX), testY)\n",
    "\n",
    "    svm = LinearSVC()\n",
    "    svm.fit(trainX, trainY)\n",
    "    svmAccuracy += accuracy_score(svm.predict(testX), testY)\n",
    "    \n",
    "    i += 1\n",
    "    \n",
    "nbAccuracy /= nFold\n",
    "svmAccuracy /= nFold\n",
    "nFeatures = int(nFeatures/nFold)\n",
    "results['features'].append('unigrams+bigrams')\n",
    "results['nFeatures'].append(nFeatures)\n",
    "results['nb'].append(nbAccuracy)\n",
    "results['svm'].append(svmAccuracy)\n",
    "\n",
    "print('Features: unigrams+position')\n",
    "print('Number of Features:', nFeatures)\n",
    "print('Naive Bayes Accuracy:', nbAccuracy)\n",
    "print('SVM Accuracy:', svmAccuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
