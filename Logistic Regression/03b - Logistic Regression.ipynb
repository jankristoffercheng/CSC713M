{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression Exercise\n",
    "\n",
    "This exercise will guide you in implementing a Linear Model for classification namely, Logistic Regression, to gain intuitions and develop a deeper understanding of classification models. These concepts will form as the foundation for more complex models later on.\n",
    "\n",
    "**You will learn to:**\n",
    "- Build the general architecture of a Logistic Regression Model.\n",
    "    - Initializing Parameters/Weights\n",
    "    - Implement the activation function that maps your raw scores to probabilities.\n",
    "    - Calculating the Cost/Loss/Objective Function\n",
    "    - Computing for the gradients of the Loss function with respect to the parameters\n",
    "    - Implement gradient descent to update the paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Fix the seed of the random number \n",
    "# generator so that your results will match ours\n",
    "np.random.seed(1)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = h5py.File(\"cat_dataset.hdf5\")\n",
    "\n",
    "train_images = data[\"train_x\"]\n",
    "y_train = np.array(data[\"train_y\"])\n",
    "test_images = data[\"test_x\"]\n",
    "y_test = np.array(data[\"test_y\"])\n",
    "\n",
    "num_train, H, W, C = train_images.shape\n",
    "num_test,_,_,_ = test_images.shape\n",
    "\n",
    "print(\"Train images shape =\", train_images.shape)\n",
    "print(\"Train labels shape =\", y_train.shape)\n",
    "print(\"Test images shape =\", test_images.shape)\n",
    "print(\"Test labels shape =\", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display random images in the training data\n",
    "randIdx = np.arange(num_train)\n",
    "np.random.shuffle(randIdx)\n",
    "plt.figure(figsize=(8,6))\n",
    "for i in range(9):\n",
    "    plt.subplot(3,3,i+1)\n",
    "    plt.imshow(train_images[randIdx[i]])\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Idx = \" + str(randIdx[i]) +\", y = \" + str(np.squeeze(y_train[randIdx[i]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(train_images,[num_train,-1])\n",
    "X_test = np.reshape(test_images,[num_test,-1])\n",
    "\n",
    "print(\"X_train shape =\",X_train.shape)\n",
    "print(\"X_test shape =\",X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Open `logistic_regression.py` and fill in the missing codes **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from logistic_regression import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = LogisticRegression()\n",
    "loss_history = classifier.train(X_train, y_train, learning_rate=5e-3, num_iters=2000, batch_size=209, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train_pred = classifier.predict(X_train)\n",
    "Y_test_pred = classifier.predict(X_test)\n",
    "print(\"Train accuracy: {} %\".format(100 - np.mean(np.abs(Y_train_pred - y_train)) * 100))\n",
    "print(\"Test accuracy: {} %\".format(100 - np.mean(np.abs(Y_test_pred - y_test)) * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_history)\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.ylabel(\"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Weights =\", classifier.params[\"W\"][0:5])\n",
    "print(\"bias =\",classifier.params[\"b\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = [\"not cat\", \"cat\"]\n",
    "\n",
    "prediction = classifier.predict(X_test[0])\n",
    "plt.imshow(test_images[4])\n",
    "plt.axis('off')\n",
    "plt.title(\"y = \" + classes[(np.squeeze(y_test[0]))] + \" | prediction =\" + classes[np.squeeze(prediction)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
