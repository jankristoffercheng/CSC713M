{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes Exercise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (12.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "# Fix the seed of the random number \n",
    "# generator so that your results will match ours\n",
    "np.random.seed(1)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris dataset\n",
    "\n",
    "The iris dataset  has 4 features with continuous values. As such, we will be using a Gaussian distribution to describe our data. \n",
    "\n",
    "How many parameters do we need to estimate for NB classification (posterior)?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width species\n",
       "0           5.1          3.5           1.4          0.2  setosa\n",
       "1           4.9          3.0           1.4          0.2  setosa\n",
       "2           4.7          3.2           1.3          0.2  setosa\n",
       "3           4.6          3.1           1.5          0.2  setosa\n",
       "4           5.0          3.6           1.4          0.2  setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# loads csv file into a pandas dataframe\n",
    "iris = pd.read_csv('iris.csv')\n",
    "\n",
    "# pd.head() displays the first 5 elements\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">petal_length</th>\n",
       "      <th colspan=\"2\" halign=\"left\">petal_width</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"2\" halign=\"left\">sepal_length</th>\n",
       "      <th colspan=\"8\" halign=\"left\">sepal_width</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>...</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>species</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>setosa</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1.464</td>\n",
       "      <td>0.173511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1.575</td>\n",
       "      <td>1.9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>0.244</td>\n",
       "      <td>...</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5.8</td>\n",
       "      <td>50.0</td>\n",
       "      <td>3.418</td>\n",
       "      <td>0.381024</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3.125</td>\n",
       "      <td>3.4</td>\n",
       "      <td>3.675</td>\n",
       "      <td>4.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>versicolor</th>\n",
       "      <td>50.0</td>\n",
       "      <td>4.260</td>\n",
       "      <td>0.469911</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.35</td>\n",
       "      <td>4.600</td>\n",
       "      <td>5.1</td>\n",
       "      <td>50.0</td>\n",
       "      <td>1.326</td>\n",
       "      <td>...</td>\n",
       "      <td>6.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.770</td>\n",
       "      <td>0.313798</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.525</td>\n",
       "      <td>2.8</td>\n",
       "      <td>3.000</td>\n",
       "      <td>3.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>virginica</th>\n",
       "      <td>50.0</td>\n",
       "      <td>5.552</td>\n",
       "      <td>0.551895</td>\n",
       "      <td>4.5</td>\n",
       "      <td>5.1</td>\n",
       "      <td>5.55</td>\n",
       "      <td>5.875</td>\n",
       "      <td>6.9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.026</td>\n",
       "      <td>...</td>\n",
       "      <td>6.9</td>\n",
       "      <td>7.9</td>\n",
       "      <td>50.0</td>\n",
       "      <td>2.974</td>\n",
       "      <td>0.322497</td>\n",
       "      <td>2.2</td>\n",
       "      <td>2.800</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.175</td>\n",
       "      <td>3.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           petal_length                                               \\\n",
       "                  count   mean       std  min  25%   50%    75%  max   \n",
       "species                                                                \n",
       "setosa             50.0  1.464  0.173511  1.0  1.4  1.50  1.575  1.9   \n",
       "versicolor         50.0  4.260  0.469911  3.0  4.0  4.35  4.600  5.1   \n",
       "virginica          50.0  5.552  0.551895  4.5  5.1  5.55  5.875  6.9   \n",
       "\n",
       "           petal_width        ...  sepal_length      sepal_width         \\\n",
       "                 count   mean ...           75%  max       count   mean   \n",
       "species                       ...                                         \n",
       "setosa            50.0  0.244 ...           5.2  5.8        50.0  3.418   \n",
       "versicolor        50.0  1.326 ...           6.3  7.0        50.0  2.770   \n",
       "virginica         50.0  2.026 ...           6.9  7.9        50.0  2.974   \n",
       "\n",
       "                                                   \n",
       "                 std  min    25%  50%    75%  max  \n",
       "species                                            \n",
       "setosa      0.381024  2.3  3.125  3.4  3.675  4.4  \n",
       "versicolor  0.313798  2.0  2.525  2.8  3.000  3.4  \n",
       "virginica   0.322497  2.2  2.800  3.0  3.175  3.8  \n",
       "\n",
       "[3 rows x 32 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.groupby('species').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4d7017bc1a56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# convert species feature from type string to integer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0miris\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"species\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"species\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# convert species feature from type string to integer\n",
    "iris[\"species\"] = pd.Categorical(iris[\"species\"]).codes\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = iris.values[:,:-1] # get everything before the species type as data X\n",
    "y = iris.values[:,-1].astype(int) # get the last column (species) as label y (from float64 to int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_items = X.shape[0]\n",
    "randIdx = np.arange(num_items)\n",
    "# randomly shuffly the indices\n",
    "np.random.shuffle(randIdx)\n",
    "\n",
    "test_percentage_split = 0.5\n",
    "\n",
    "num_test = np.ceil(num_items * test_percentage_split).astype(int)\n",
    "X_test = X[randIdx[0:num_test]]\n",
    "y_test = y[randIdx[0:num_test]]\n",
    "\n",
    "X_train = X[randIdx[num_test:]]\n",
    "y_train = y[randIdx[num_test:]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier (Gaussian)\n",
    "\n",
    "Open naive_bayes.py and implement the TODOs for Gaussian distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from naive_bayes import NaiveBayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gaussian_nb = NaiveBayes(distribution=\"gaussian\")\n",
    "gaussian_nb.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculate for the accuracy of the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6229c71d8f0c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnum_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "np.sum(y_test == predictions) / num_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Spam/Not-Spam dataset\n",
    "\n",
    "The spam/not-spam dataset are data taken from spam and non-spam emails. Based on the words used, we want to classify whether the email is spam or not spam.\n",
    "\n",
    "In this dataset, we just look at how frequent a chosen 2,500 words appear per document.\n",
    "\n",
    "\n",
    "How many parameters do we need to estimate for NB classification (posterior)?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "train_spam_dir = \"lingspam/spam-train/\"\n",
    "train_nonspam_dir = \"lingspam/nonspam-train/\"\n",
    "test_spam_dir = \"lingspam/spam-test/\"\n",
    "test_nonspam_dir = \"lingspam/nonspam-test/\"\n",
    "\n",
    "global_word_dict = {}\n",
    "train_doc_word_list = []\n",
    "test_doc_word_list = []\n",
    "for folder in [train_spam_dir, train_nonspam_dir, test_spam_dir, test_nonspam_dir]:\n",
    "    for file in os.listdir(folder):\n",
    "        tmp_doc_word = {}\n",
    "        with open(folder + file,\"r\") as f:\n",
    "            words = f.read().split(\" \")\n",
    "\n",
    "            for word in words:\n",
    "                word = word.strip()\n",
    "                if len(word) > 1:\n",
    "                    if word in global_word_dict:\n",
    "                        global_word_dict[word] += 1\n",
    "                    else:\n",
    "                        global_word_dict[word] = 1\n",
    "                        \n",
    "                    if word in tmp_doc_word:\n",
    "                        tmp_doc_word[word] += 1\n",
    "                    else:\n",
    "                        tmp_doc_word[word] = 1\n",
    "                \n",
    "                \n",
    "            if folder == train_spam_dir:\n",
    "                train_doc_word_list.append({'words': tmp_doc_word, 'label': 1})\n",
    "            elif folder == train_nonspam_dir:\n",
    "                train_doc_word_list.append({'words': tmp_doc_word, 'label': 0})\n",
    "            elif folder == test_spam_dir:\n",
    "                test_doc_word_list.append({'words': tmp_doc_word, 'label': 1})\n",
    "            elif folder == test_nonspam_dir:\n",
    "                test_doc_word_list.append({'words': tmp_doc_word, 'label': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted_words = []\n",
    "sorted_counts = []\n",
    "for key in sorted(global_word_dict, key=global_word_dict.get, reverse=True):\n",
    "    sorted_words.append(key)\n",
    "    sorted_counts.append(global_word_dict[key])\n",
    "vocab_size = 2500\n",
    "vocabulary = sorted_words[0:vocab_size]\n",
    "vocab_counts = sorted_counts[0:vocab_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['email',\n",
       " 'order',\n",
       " 'address',\n",
       " 'language',\n",
       " 'report',\n",
       " 'mail',\n",
       " 'our',\n",
       " 'university',\n",
       " 'send',\n",
       " 'program']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = len(train_doc_word_list)\n",
    "X_train = np.zeros((num_train, vocab_size))\n",
    "y_train = np.zeros(num_train)\n",
    "for i in range(num_train):  \n",
    "    y_train[i] = train_doc_word_list[i]['label']\n",
    "    \n",
    "    for j in range(len(vocabulary)):\n",
    "        word = vocabulary[j]\n",
    "        if word in train_doc_word_list[i]['words']:\n",
    "            X_train[i,j] = train_doc_word_list[i]['words'][word]\n",
    "        else:\n",
    "            X_train[i,j] = 0\n",
    "            \n",
    "num_test = len(test_doc_word_list)\n",
    "X_test = np.zeros((num_test, vocab_size))\n",
    "y_test = np.zeros(num_test)\n",
    "for i in range(num_test):  \n",
    "    y_test[i] = test_doc_word_list[i]['label']\n",
    "    \n",
    "    for j in range(len(vocabulary)):\n",
    "        word = vocabulary[j]\n",
    "        if word in test_doc_word_list[i]['words']:\n",
    "            X_test[i,j] = test_doc_word_list[i]['words'][word]\n",
    "        else:\n",
    "            X_test[i,j] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier (Multinomial)\n",
    "\n",
    "Open naive_bayes.py and implement the TODOs for multinomial distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "multinomial_nb = NaiveBayes(distribution=\"multinomial\")\n",
    "multinomial_nb.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = multinomial_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98076923076923073"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(y_test == pred) / num_test"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
